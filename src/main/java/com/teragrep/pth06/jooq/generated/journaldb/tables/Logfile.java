/*
 * This program handles user requests that require archive access.
 * Copyright (C) 2022  Suomen Kanuuna Oy
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program.  If not, see <https://github.com/teragrep/teragrep/blob/main/LICENSE>.
 *
 *
 * Additional permission under GNU Affero General Public License version 3
 * section 7
 *
 * If you modify this Program, or any covered work, by linking or combining it
 * with other code, such other code is not for that reason alone subject to any
 * of the requirements of the GNU Affero GPL version 3 as long as this Program
 * is the same Program as licensed from Suomen Kanuuna Oy without any additional
 * modifications.
 *
 * Supplemented terms under GNU Affero General Public License version 3
 * section 7
 *
 * Origin of the software must be attributed to Suomen Kanuuna Oy. Any modified
 * versions must be marked as "Modified version of" The Program.
 *
 * Names of the licensors and authors may not be used for publicity purposes.
 *
 * No rights are granted for use of trade names, trademarks, or service marks
 * which are in The Program if any.
 *
 * Licensee must indemnify licensors and authors for any liability that these
 * contractual assumptions impose on licensors and authors.
 *
 * To the extent this program is licensed as part of the Commercial versions of
 * Teragrep, the applicable Commercial License may apply to this file if you as
 * a licensee so wish it.
 */
/*
 * This file is generated by jOOQ.
 */
package com.teragrep.pth06.jooq.generated.journaldb.tables;


import com.teragrep.pth06.jooq.generated.journaldb.Indexes;
import com.teragrep.pth06.jooq.generated.journaldb.Journaldb;
import com.teragrep.pth06.jooq.generated.journaldb.Keys;
import com.teragrep.pth06.jooq.generated.journaldb.tables.records.LogfileRecord;

import java.sql.Date;
import java.sql.Timestamp;
import java.util.Arrays;
import java.util.List;

import javax.annotation.Generated;

import org.jooq.Field;
import org.jooq.ForeignKey;
import org.jooq.Identity;
import org.jooq.Index;
import org.jooq.Name;
import org.jooq.Record;
import org.jooq.Row16;
import org.jooq.Schema;
import org.jooq.Table;
import org.jooq.TableField;
import org.jooq.UniqueKey;
import org.jooq.impl.DSL;
import org.jooq.impl.TableImpl;
import org.jooq.types.ULong;
import org.jooq.types.UShort;


/**
 * Contains information for log files that have been run through Log Archiver
 */
@Generated(
    value = {
        "http://www.jooq.org",
        "jOOQ version:3.12.4"
    },
    comments = "This class is generated by jOOQ"
)
@SuppressWarnings({ "all", "unchecked", "rawtypes" })
public class Logfile extends TableImpl<LogfileRecord> {

    private static final long serialVersionUID = -1131541473;

    /**
     * The reference instance of <code>journaldb.logfile</code>
     */
    public static final Logfile LOGFILE = new Logfile();

    /**
     * The class holding records for this type
     */
    @Override
    public Class<LogfileRecord> getRecordType() {
        return LogfileRecord.class;
    }

    /**
     * The column <code>journaldb.logfile.id</code>.
     */
    public final TableField<LogfileRecord, ULong> ID = createField(DSL.name("id"), org.jooq.impl.SQLDataType.BIGINTUNSIGNED.nullable(false).identity(true), this, "");

    /**
     * The column <code>journaldb.logfile.logdate</code>. Log file's date
     */
    public final TableField<LogfileRecord, Date> LOGDATE = createField(DSL.name("logdate"), org.jooq.impl.SQLDataType.DATE.nullable(false), this, "Log file's date");

    /**
     * The column <code>journaldb.logfile.expiration</code>. Log file's expiration date
     */
    public final TableField<LogfileRecord, Date> EXPIRATION = createField(DSL.name("expiration"), org.jooq.impl.SQLDataType.DATE.nullable(false), this, "Log file's expiration date");

    /**
     * The column <code>journaldb.logfile.bucket_id</code>. Reference to bucket table
     */
    public final TableField<LogfileRecord, UShort> BUCKET_ID = createField(DSL.name("bucket_id"), org.jooq.impl.SQLDataType.SMALLINTUNSIGNED.nullable(false), this, "Reference to bucket table");

    /**
     * The column <code>journaldb.logfile.path</code>. Log file's path in object storage
     */
    public final TableField<LogfileRecord, String> PATH = createField(DSL.name("path"), org.jooq.impl.SQLDataType.VARCHAR(2048).nullable(false), this, "Log file's path in object storage");

    /**
     * The column <code>journaldb.logfile.object_key_hash</code>. Hash of path and bucket_id for uniqueness checks. Known length: 64 characters (SHA-256)
     */
    public final TableField<LogfileRecord, String> OBJECT_KEY_HASH = createField(DSL.name("object_key_hash"), org.jooq.impl.SQLDataType.CHAR(64).defaultValue(org.jooq.impl.DSL.field("NULL", org.jooq.impl.SQLDataType.CHAR)), this, "Hash of path and bucket_id for uniqueness checks. Known length: 64 characters (SHA-256)");

    /**
     * The column <code>journaldb.logfile.host_id</code>. Reference to host table
     */
    public final TableField<LogfileRecord, UShort> HOST_ID = createField(DSL.name("host_id"), org.jooq.impl.SQLDataType.SMALLINTUNSIGNED.nullable(false), this, "Reference to host table");

    /**
     * The column <code>journaldb.logfile.original_filename</code>. Log file's original file name
     */
    public final TableField<LogfileRecord, String> ORIGINAL_FILENAME = createField(DSL.name("original_filename"), org.jooq.impl.SQLDataType.VARCHAR(255).nullable(false), this, "Log file's original file name");

    /**
     * The column <code>journaldb.logfile.archived</code>. Date and time when the log file was archived
     */
    public final TableField<LogfileRecord, Timestamp> ARCHIVED = createField(DSL.name("archived"), org.jooq.impl.SQLDataType.TIMESTAMP.nullable(false), this, "Date and time when the log file was archived");

    /**
     * The column <code>journaldb.logfile.file_size</code>. Log file's size in bytes
     */
    public final TableField<LogfileRecord, ULong> FILE_SIZE = createField(DSL.name("file_size"), org.jooq.impl.SQLDataType.BIGINTUNSIGNED.nullable(false).defaultValue(org.jooq.impl.DSL.field("0", org.jooq.impl.SQLDataType.BIGINTUNSIGNED)), this, "Log file's size in bytes");

    /**
     * The column <code>journaldb.logfile.sha256_checksum</code>. An SHA256 hash of the log file (Note: known to be 44 characters long)
     */
    public final TableField<LogfileRecord, String> SHA256_CHECKSUM = createField(DSL.name("sha256_checksum"), org.jooq.impl.SQLDataType.CHAR(44).nullable(false), this, "An SHA256 hash of the log file (Note: known to be 44 characters long)");

    /**
     * The column <code>journaldb.logfile.archive_etag</code>. Object storage's MD5 hash of the log file (Note: room left for possible implementation changes)
     */
    public final TableField<LogfileRecord, String> ARCHIVE_ETAG = createField(DSL.name("archive_etag"), org.jooq.impl.SQLDataType.VARCHAR(64).nullable(false), this, "Object storage's MD5 hash of the log file (Note: room left for possible implementation changes)");

    /**
     * The column <code>journaldb.logfile.logtag</code>. A link back to CFEngine
     */
    public final TableField<LogfileRecord, String> LOGTAG = createField(DSL.name("logtag"), org.jooq.impl.SQLDataType.VARCHAR(48).nullable(false), this, "A link back to CFEngine");

    /**
     * The column <code>journaldb.logfile.source_system_id</code>. Log file's source system (references source_system.id)
     */
    public final TableField<LogfileRecord, UShort> SOURCE_SYSTEM_ID = createField(DSL.name("source_system_id"), org.jooq.impl.SQLDataType.SMALLINTUNSIGNED.nullable(false), this, "Log file's source system (references source_system.id)");

    /**
     * The column <code>journaldb.logfile.category_id</code>. Log file's category (references category.id)
     */
    public final TableField<LogfileRecord, UShort> CATEGORY_ID = createField(DSL.name("category_id"), org.jooq.impl.SQLDataType.SMALLINTUNSIGNED.nullable(false).defaultValue(org.jooq.impl.DSL.field("0", org.jooq.impl.SQLDataType.SMALLINTUNSIGNED)), this, "Log file's category (references category.id)");

    /**
     * The column <code>journaldb.logfile.uncompressed_file_size</code>. Log file's  uncompressed file size
     */
    public final TableField<LogfileRecord, ULong> UNCOMPRESSED_FILE_SIZE = createField(DSL.name("uncompressed_file_size"), org.jooq.impl.SQLDataType.BIGINTUNSIGNED.defaultValue(org.jooq.impl.DSL.field("NULL", org.jooq.impl.SQLDataType.BIGINTUNSIGNED)), this, "Log file's  uncompressed file size");

    /**
     * Create a <code>journaldb.logfile</code> table reference
     */
    public Logfile() {
        this(DSL.name("logfile"), null);
    }

    /**
     * Create an aliased <code>journaldb.logfile</code> table reference
     */
    public Logfile(String alias) {
        this(DSL.name(alias), LOGFILE);
    }

    /**
     * Create an aliased <code>journaldb.logfile</code> table reference
     */
    public Logfile(Name alias) {
        this(alias, LOGFILE);
    }

    private Logfile(Name alias, Table<LogfileRecord> aliased) {
        this(alias, aliased, null);
    }

    private Logfile(Name alias, Table<LogfileRecord> aliased, Field<?>[] parameters) {
        super(alias, null, aliased, parameters, DSL.comment("Contains information for log files that have been run through Log Archiver"));
    }

    public <O extends Record> Logfile(Table<O> child, ForeignKey<O, LogfileRecord> key) {
        super(child, key, LOGFILE);
    }

    @Override
    public Schema getSchema() {
        return Journaldb.JOURNALDB;
    }

    @Override
    public List<Index> getIndexes() {
        return Arrays.<Index>asList(Indexes.LOGFILE_BUCKET_ID, Indexes.LOGFILE_CATEGORY_ID, Indexes.LOGFILE_CIX_LOGFILE_HOST_ID_LOGTAG_LOGDATE, Indexes.LOGFILE_CIX_LOGFILE_LOGDATE_HOST_ID_LOGTAG, Indexes.LOGFILE_HOST_ID, Indexes.LOGFILE_IX_LOGFILE_EXPIRATION, Indexes.LOGFILE_IX_LOGFILE__SOURCE_SYSTEM_ID, Indexes.LOGFILE_PRIMARY, Indexes.LOGFILE_UIX_LOGFILE_OBJECT_HASH);
    }

    @Override
    public Identity<LogfileRecord, ULong> getIdentity() {
        return Keys.IDENTITY_LOGFILE;
    }

    @Override
    public UniqueKey<LogfileRecord> getPrimaryKey() {
        return Keys.KEY_LOGFILE_PRIMARY;
    }

    @Override
    public List<UniqueKey<LogfileRecord>> getKeys() {
        return Arrays.<UniqueKey<LogfileRecord>>asList(Keys.KEY_LOGFILE_PRIMARY, Keys.KEY_LOGFILE_UIX_LOGFILE_OBJECT_HASH);
    }

    @Override
    public List<ForeignKey<LogfileRecord, ?>> getReferences() {
        return Arrays.<ForeignKey<LogfileRecord, ?>>asList(Keys.LOGFILE_IBFK_1, Keys.LOGFILE_IBFK_2);
    }

    public Bucket bucket() {
        return new Bucket(this, Keys.LOGFILE_IBFK_1);
    }

    public Host host() {
        return new Host(this, Keys.LOGFILE_IBFK_2);
    }

    @Override
    public Logfile as(String alias) {
        return new Logfile(DSL.name(alias), this);
    }

    @Override
    public Logfile as(Name alias) {
        return new Logfile(alias, this);
    }

    /**
     * Rename this table
     */
    @Override
    public Logfile rename(String name) {
        return new Logfile(DSL.name(name), null);
    }

    /**
     * Rename this table
     */
    @Override
    public Logfile rename(Name name) {
        return new Logfile(name, null);
    }

    // -------------------------------------------------------------------------
    // Row16 type methods
    // -------------------------------------------------------------------------

    @Override
    public Row16<ULong, Date, Date, UShort, String, String, UShort, String, Timestamp, ULong, String, String, String, UShort, UShort, ULong> fieldsRow() {
        return (Row16) super.fieldsRow();
    }
}
